{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5386551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63fa92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VitalSignsPredictor:\n",
    "    def __init__(self, sequence_length=60, feature_dim=5):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.feature_dim = feature_dim\n",
    "        self.scalers = {}\n",
    "\n",
    "    def create_model(self):\n",
    "        # Input layer\n",
    "        inputs = keras.Input(\n",
    "            shape=(self.sequence_length, self.feature_dim), name=\"vital_signs\"\n",
    "        )\n",
    "\n",
    "        # Feature indices\n",
    "        # Assuming feature order: [art, ecg, pleth, co2, phen]\n",
    "        ART_IDX, ECG_IDX, PLETH_IDX, CO2_IDX, PHEN_IDX = 0, 1, 2, 3, 4\n",
    "\n",
    "        # Main feature processing branch\n",
    "        x = layers.LSTM(128, return_sequences=True, dropout=0.2)(inputs)\n",
    "        x = layers.LSTM(64, return_sequences=False, dropout=0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        # Branch 1: Prediction with phenylephrine\n",
    "        # Use all features including phen\n",
    "        with_phen_features = layers.Dense(64, activation=\"relu\")(x)\n",
    "        with_phen_features = layers.Dropout(0.3)(with_phen_features)\n",
    "        with_phen_features = layers.Dense(32, activation=\"relu\")(with_phen_features)\n",
    "        output_with_phen = layers.Dense(1, name=\"prediction_with_phen\")(\n",
    "            with_phen_features\n",
    "        )\n",
    "\n",
    "        # Branch 2: Prediction without phenylephrine\n",
    "        # Create a modified version without phen feature\n",
    "        # We'll use a separate processing branch that focuses on non-phen features\n",
    "        without_phen_branch = layers.LSTM(128, return_sequences=True, dropout=0.2)(\n",
    "            inputs\n",
    "        )\n",
    "        without_phen_branch = layers.LSTM(64, return_sequences=False, dropout=0.2)(\n",
    "            without_phen_branch\n",
    "        )\n",
    "        without_phen_branch = layers.BatchNormalization()(without_phen_branch)\n",
    "\n",
    "        without_phen_features = layers.Dense(64, activation=\"relu\")(without_phen_branch)\n",
    "        without_phen_features = layers.Dropout(0.3)(without_phen_features)\n",
    "        without_phen_features = layers.Dense(32, activation=\"relu\")(\n",
    "            without_phen_features\n",
    "        )\n",
    "        output_without_phen = layers.Dense(1, name=\"prediction_without_phen\")(\n",
    "            without_phen_features\n",
    "        )\n",
    "\n",
    "        # Create model\n",
    "        model = keras.Model(\n",
    "            inputs=inputs, outputs=[output_with_phen, output_without_phen]\n",
    "        )\n",
    "\n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss={\"prediction_with_phen\": \"mse\", \"prediction_without_phen\": \"mse\"},\n",
    "            loss_weights={\"prediction_with_phen\": 1.0, \"prediction_without_phen\": 1.0},\n",
    "            metrics={\n",
    "                \"prediction_with_phen\": [\"mae\"],\n",
    "                \"prediction_without_phen\": [\"mae\"],\n",
    "            },\n",
    "        )\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b903025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(self, data, target_col=\"art\"):\n",
    "    \"\"\"\n",
    "    Prepare time series data for training\n",
    "    data: DataFrame with columns [art, ecg, pleth, co2, phen]\n",
    "    \"\"\"\n",
    "    # Create sequences\n",
    "    sequences = []\n",
    "    targets_with_phen = []\n",
    "    targets_without_phen = []\n",
    "\n",
    "    for i in range(len(data) - self.sequence_length):\n",
    "        seq = data.iloc[i : i + self.sequence_length].values\n",
    "        target = data.iloc[i + self.sequence_length][target_col]\n",
    "\n",
    "        sequences.append(seq)\n",
    "        targets_with_phen.append(target)\n",
    "        targets_without_phen.append(target)\n",
    "\n",
    "    sequences = np.array(sequences)\n",
    "    targets_with_phen = np.array(targets_with_phen)\n",
    "    targets_without_phen = np.array(targets_without_phen)\n",
    "\n",
    "    return sequences, targets_with_phen, targets_without_phen\n",
    "\n",
    "\n",
    "def fit_scalers(self, data):\n",
    "    \"\"\"Fit scalers for each feature\"\"\"\n",
    "    for i, col in enumerate(data.columns):\n",
    "        self.scalers[i] = StandardScaler()\n",
    "        self.scalers[i].fit(data[[col]])\n",
    "\n",
    "\n",
    "def scale_data(self, data):\n",
    "    \"\"\"Scale data using fitted scalers\"\"\"\n",
    "    scaled_data = data.copy()\n",
    "    for i, col in enumerate(data.columns):\n",
    "        scaled_data[col] = self.scalers[i].transform(data[[col]])\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfaa583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage and training\n",
    "def main():\n",
    "    # Assuming you have your data loaded as a DataFrame\n",
    "    # data = pd.read_csv('your_vitaldb_data.csv')\n",
    "    # For demonstration, creating sample data\n",
    "    np.random.seed(42)\n",
    "    n_samples = 10000\n",
    "    data = pd.DataFrame(\n",
    "        {\n",
    "            \"art\": np.random.normal(120, 20, n_samples),\n",
    "            \"ecg\": np.random.normal(70, 10, n_samples),\n",
    "            \"pleth\": np.random.normal(95, 5, n_samples),\n",
    "            \"co2\": np.random.normal(40, 5, n_samples),\n",
    "            \"phen\": np.random.normal(0, 1, n_samples),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Initialize predictor\n",
    "    predictor = VitalSignsPredictor(sequence_length=60, feature_dim=5)\n",
    "\n",
    "    # Prepare data\n",
    "    predictor.fit_scalers(data)\n",
    "    scaled_data = predictor.scale_data(data)\n",
    "\n",
    "    sequences, targets_with_phen, targets_without_phen = predictor.prepare_data(\n",
    "        scaled_data\n",
    "    )\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y1_train, y1_test, y2_train, y2_test = train_test_split(\n",
    "        sequences,\n",
    "        targets_with_phen,\n",
    "        targets_without_phen,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    # Create and train model\n",
    "    model = predictor.create_model()\n",
    "\n",
    "    # Print model architecture\n",
    "    model.summary()\n",
    "\n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5),\n",
    "    ]\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        {\"prediction_with_phen\": y1_train, \"prediction_without_phen\": y2_train},\n",
    "        validation_data=(\n",
    "            X_test,\n",
    "            {\"prediction_with_phen\": y1_test, \"prediction_without_phen\": y2_test},\n",
    "        ),\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    return model, predictor, history\n",
    "\n",
    "\n",
    "# Alternative simpler model architecture\n",
    "def create_simpler_model(sequence_length=60, feature_dim=5):\n",
    "    \"\"\"Alternative simpler architecture\"\"\"\n",
    "    inputs = keras.Input(shape=(sequence_length, feature_dim))\n",
    "\n",
    "    # Shared LSTM layers\n",
    "    x = layers.LSTM(64, return_sequences=True, dropout=0.2)(inputs)\n",
    "    x = layers.LSTM(32, return_sequences=False, dropout=0.2)(x)\n",
    "\n",
    "    # Branch with phen\n",
    "    with_phen = layers.Dense(32, activation=\"relu\")(x)\n",
    "    with_phen = layers.Dropout(0.3)(with_phen)\n",
    "    output_with_phen = layers.Dense(1, name=\"prediction_with_phen\")(with_phen)\n",
    "\n",
    "    # Branch without phen - using same shared features but different output head\n",
    "    without_phen = layers.Dense(32, activation=\"relu\")(x)\n",
    "    without_phen = layers.Dropout(0.3)(without_phen)\n",
    "    output_without_phen = layers.Dense(1, name=\"prediction_without_phen\")(without_phen)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=[output_with_phen, output_without_phen])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss={\"prediction_with_phen\": \"mse\", \"prediction_without_phen\": \"mse\"},\n",
    "        metrics={\"prediction_with_phen\": [\"mae\"], \"prediction_without_phen\": [\"mae\"]},\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# For prediction on new data\n",
    "def predict_new_data(model, predictor, new_data):\n",
    "    \"\"\"Make predictions on new data\"\"\"\n",
    "    scaled_data = predictor.scale_data(new_data)\n",
    "    sequences, _, _ = predictor.prepare_data(scaled_data)\n",
    "\n",
    "    predictions = model.predict(sequences)\n",
    "    pred_with_phen, pred_without_phen = predictions\n",
    "\n",
    "    return pred_with_phen, pred_without_phen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66212bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model, predictor, history = main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
